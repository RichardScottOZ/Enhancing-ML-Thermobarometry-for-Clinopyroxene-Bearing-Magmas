{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d78ade",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db237b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T11:34:42.856263Z",
     "start_time": "2024-03-14T11:34:42.842060Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import scipy.stats as st\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import convert_sklearn\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import gaussian_kde\n",
    "import onnxruntime as rt\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ML_PT_Pyworkflow import*\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290ed2e4",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2ec77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T11:34:43.883460Z",
     "start_time": "2024-03-14T11:34:43.877141Z"
    }
   },
   "outputs": [],
   "source": [
    "cpx_only   = True  # True or False for Liquid\n",
    "pwlt       = False # or False\n",
    "output     = 'Temperature' # 'Temperature'or 'Pressure'\n",
    "bias       = True  # True or False\n",
    "chromium   = True      # or False\n",
    "p          = 1000  # number of perturbations in test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e2e1c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:18:10.794415Z",
     "start_time": "2023-11-27T14:18:10.789633Z"
    }
   },
   "source": [
    "# Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b877ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T11:34:44.456310Z",
     "start_time": "2024-03-14T11:34:44.440838Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "df_init = Dataset.Jorgenson\n",
    "\n",
    "Elements_Cpx = ['SiO2_Cpx', 'TiO2_Cpx', 'Al2O3_Cpx', 'FeOt_Cpx', 'MgO_Cpx', 'MnO_Cpx', 'CaO_Cpx',  'Na2O_Cpx', 'Cr2O3_Cpx']\n",
    "Elements_Liq = ['SiO2_Liq', 'TiO2_Liq', 'Al2O3_Liq', 'FeOt_Liq', 'MgO_Liq', 'MnO_Liq', 'CaO_Liq',  'Na2O_Liq', 'K2O_Liq']\n",
    "\n",
    "if cpx_only:\n",
    "    columns_name = Elements_Cpx.copy()\n",
    "    columns_name = columns_name if chromium else [x for x in columns_name if 'Cr' not in x]\n",
    "    df = df_init[columns_name]\n",
    "    sample_names = df_init['Sample_ID']### I added this\n",
    "else:\n",
    "    columns_name = Elements_Cpx.copy() + Elements_Liq.copy()\n",
    "    columns_name = columns_name if chromium else [x for x in columns_name if 'Cr' not in x]\n",
    "    df = df_init[columns_name]\n",
    "    sample_names = df_init['Sample_ID'] ####### I added this\n",
    "    sum_liq = np.reshape(np.array(df_init[Elements_Liq].sum(axis=1)),(len(df_init),1))\n",
    "\n",
    "\n",
    "Xd = df\n",
    "    \n",
    "if output == 'Pressure':\n",
    "    yd = df_init['P_kbar']\n",
    "elif output == 'Temperature':\n",
    "    yd = df_init['T_C']\n",
    "else:\n",
    "    print('We can just menage Pressure or Temperature')\n",
    "\n",
    "X = np.array(Xd)\n",
    "y = np.array(yd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9a1d44",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11571cb1",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85a95b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T11:34:47.001293Z",
     "start_time": "2024-03-14T11:34:46.993102Z"
    }
   },
   "outputs": [],
   "source": [
    "std_dev_perc = Parameters.oxide_rel_err\n",
    "K = Parameters.K_rel_err\n",
    "\n",
    "\n",
    "if cpx_only:\n",
    "    std_dev_perc = std_dev_perc if chromium else std_dev_perc[:-1]\n",
    "    \n",
    "else:\n",
    "    std_dev_perc_temp_1 = std_dev_perc if chromium else std_dev_perc[:-1]\n",
    "    std_dev_perc_temp_2 = std_dev_perc[:-1]\n",
    "    std_dev_perc = np.concatenate((std_dev_perc_temp_1,std_dev_perc_temp_2,K),axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423736dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T11:34:47.586509Z",
     "start_time": "2024-03-14T11:34:47.580754Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bins to manage unbalanced float numbers as output \n",
    "\n",
    "if output == 'Pressure':\n",
    "    bins = Parameters.pressure_bins\n",
    "elif output == 'Temperature':\n",
    "    bins = Parameters.temperature_bins\n",
    "else:\n",
    "    print('We can just menage Pressure or Temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b89b1a",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67814ac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T11:34:49.822406Z",
     "start_time": "2024-03-14T11:34:49.812846Z"
    }
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test, train_index, test_index = balanced_train_test(X,y,bins,test_size, sample_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63c3b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T11:34:50.592485Z",
     "start_time": "2024-03-14T11:34:50.586533Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rescaling input features\n",
    "scaler = StandardScaler().fit(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2dbe54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T11:34:51.490342Z",
     "start_time": "2024-03-14T11:34:51.029648Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_perturb, y_test_perturb, groups_test = perturbation(X_test\n",
    "                                                           ,y_test\n",
    "                                                           ,std_dev_perc \n",
    "                                                           ,n_perturbations=p)\n",
    "if pwlt:\n",
    "    X_test_perturb_s = pwlt_transformation(X_test_perturb)\n",
    "    X_test_s = pwlt_transformation(X_test)\n",
    "else:\n",
    "    X_test_perturb_s = scaler.transform(X_test_perturb)\n",
    "    X_test_s = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b035649",
   "metadata": {},
   "source": [
    "## Train & Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d423db",
   "metadata": {},
   "source": [
    "### Main Model: Hyperparameters fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a23adac-5647-4a7f-b8f9-ba1ccdb18c89",
   "metadata": {},
   "source": [
    "#### n_estimators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe1d5a4-060b-4137-ab73-1996416a63d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=datetime.now() \n",
    "\n",
    "n_perturbations = 15\n",
    "k_fold = 10\n",
    "max_depth = 15\n",
    "\n",
    "i_tot = []\n",
    "j_tot = []\n",
    "score_perturb_train_val_tot = []\n",
    "score_train_val_tot = []\n",
    "\n",
    "for i in [1,3,5,8,10,15,20,25,30,35,40,45,50,100,150,200,250,300,350]:\n",
    "        \n",
    "    model_ET_perturb, score_perturb_train_val = ET_train_validation_balanced_perturbation(X_train\n",
    "                                                                                          ,y_train\n",
    "                                                                                          ,std_dev_perc\n",
    "                                                                                          ,bins\n",
    "                                                                                          ,k_fold=k_fold\n",
    "                                                                                          ,n_estimators=i\n",
    "                                                                                          ,max_depth=max_depth\n",
    "                                                                                          ,n_perturbations=n_perturbations\n",
    "                                                                                          ,pwlt=pwlt)\n",
    "    model_ET, score_train_val = ET_train_validation_balanced(X_train\n",
    "                                                             ,y_train\n",
    "                                                             ,bins\n",
    "                                                             ,k_fold=k_fold\n",
    "                                                             ,n_estimators=i\n",
    "                                                             ,max_depth=max_depth\n",
    "                                                             ,pwlt=pwlt)\n",
    "\n",
    "   \n",
    "    \n",
    "    i_tot.append(i)\n",
    "    score_perturb_train_val_tot.append(score_perturb_train_val)\n",
    "    score_train_val_tot.append(score_train_val)\n",
    "    \n",
    "    print('i-param:',i)\n",
    "    print('score-model-perturb_train_val:',score_perturb_train_val)\n",
    "    print('score-model_train_val:',score_train_val)\n",
    "    print('################')\n",
    "    \n",
    "print(datetime.now()-start)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3f54f4-591f-4985-a794-a6d808e4d702",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax) = plt.subplots(nrows=1, ncols=1, constrained_layout=True, figsize=(5, 5))\n",
    "sns.lineplot(x=i_tot, y=score_train_val_tot)\n",
    "ax.set_xlabel('Number of Estimators', fontsize=12)\n",
    "ax.set_ylabel('Score model' , fontsize=12)\n",
    "ax.grid(color='#B2B2B2', linestyle='--', linewidth=0.5, alpha=0.4)\n",
    "ax.set_title('Not augmented model')\n",
    "ax.legend(title = 'Max. Depth = 15', loc='lower right')\n",
    "ax.set_box_aspect(1)\n",
    "#plt.savefig('Figures/'+'Cpx_hyperp_nTrees_NotPropModel_'+output+ ('_cpx_only' if cpx_only else '_cpx_liq') + ('_pwlr_' if pwlt else '_') +'.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b934b05-39a4-4e76-b362-f2f4d0140150",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax) = plt.subplots(nrows=1, ncols=1, constrained_layout=True, figsize=(5, 5))\n",
    "sns.lineplot(x=i_tot, y=score_perturb_train_val_tot)\n",
    "ax.set_xlabel('Number of Estimators', fontsize=12)\n",
    "ax.set_ylabel('Score model', fontsize=12)\n",
    "ax.grid(color='#B2B2B2', linestyle='--', linewidth=0.5, alpha=0.4)\n",
    "ax.set_title('Augmented model: '+ ('cpx ' if cpx_only else '_cpx_liq')+output)\n",
    "ax.legend(title = 'Max. Depth = 15', loc='lower right')\n",
    "ax.set_box_aspect(1)\n",
    "plt.savefig('Figures/'+'Cpx_hyperp_nTrees_PropModel_'+output+ ('_cpx_only' if cpx_only else '_cpx_liq') + ('_pwlr_' if pwlt else '_') +'.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f2ced-e93d-4e3c-8d82-47c4f6dcb28c",
   "metadata": {},
   "source": [
    "#### Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ce45b-5516-4233-a3f4-0d8450ee3a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=datetime.now() \n",
    "\n",
    "n_perturbations = 15\n",
    "k_fold = 10\n",
    "n_estimators = 200\n",
    "i_tot = []\n",
    "j_tot = []\n",
    "score_perturb_train_val_tot = []\n",
    "score_train_val_tot = []\n",
    "\n",
    "for i in range(1,25):\n",
    "    model_ET_perturb, score_perturb_train_val = ET_train_validation_balanced_perturbation(X_train\n",
    "                                                                                          ,y_train\n",
    "                                                                                          ,std_dev_perc\n",
    "                                                                                          ,bins\n",
    "                                                                                          ,k_fold=k_fold\n",
    "                                                                                          ,n_estimators=n_estimators\n",
    "                                                                                          ,max_depth=i\n",
    "                                                                                          ,n_perturbations=n_perturbations\n",
    "                                                                                          ,pwlt=pwlt)\n",
    "\n",
    "    model_ET, score_train_val = ET_train_validation_balanced(X_train\n",
    "                                                             ,y_train\n",
    "                                                             ,bins\n",
    "                                                             ,k_fold=k_fold\n",
    "                                                             ,n_estimators=n_estimators\n",
    "                                                             ,max_depth=i\n",
    "                                                             ,pwlt=pwlt)\n",
    "\n",
    "\n",
    "    i_tot.append(i)\n",
    "    score_perturb_train_val_tot.append(score_perturb_train_val)\n",
    "    score_train_val_tot.append(score_train_val)\n",
    "    print('i-param:',i)\n",
    "    print('score-model-perturb_train_val:',score_perturb_train_val)\n",
    "    print('score-model_train_val:',score_train_val)\n",
    "    print('################')\n",
    "    \n",
    "print(datetime.now()-start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3245c20c-829a-4194-868b-7df3e8fd6883",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax) = plt.subplots(nrows=1, ncols=1, constrained_layout=True, figsize=(5, 5))\n",
    "sns.lineplot(x=i_tot, y=score_train_val_tot, color='#1B3C73')\n",
    "ax.set_xlabel('Max. Depth', fontsize=12)\n",
    "ax.set_ylabel('Score model' , fontsize=12)\n",
    "ax.grid(color='#B2B2B2', linestyle='--', linewidth=0.5, alpha=0.4)\n",
    "ax.set_title('Not Propagated model')\n",
    "ax.legend(title = 'N. Estimators = 200', loc='lower right')\n",
    "ax.set_box_aspect(1)\n",
    "#plt.savefig('Figures/'+'Cpx_hyperp_maxDepth_NotPropModel'+output+ ('_cpx_only' if cpx_only else '_cpx_liq') + ('_pwlr_' if pwlt else '') +'.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996edf38-5a45-40c4-91c5-051e6e6b5690",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax) = plt.subplots(nrows=1, ncols=1, constrained_layout=True, figsize=(5, 5))\n",
    "sns.lineplot(x=i_tot, y=score_perturb_train_val_tot)\n",
    "ax.set_xlabel('Max. Depth', fontsize=12)\n",
    "ax.set_ylabel('Score model' , fontsize=12)\n",
    "ax.grid(color='#B2B2B2', linestyle='--', linewidth=0.5, alpha=0.4)\n",
    "ax.set_title('Augmented model: '+ ('cpx ' if cpx_only else '_cpx_liq')+output)\n",
    "ax.legend(title = 'N. Estimators = 200', loc='lower right')\n",
    "ax.set_box_aspect(1)\n",
    "#plt.savefig('Figures/'+'Cpx_hyperp_maxDepth_PropModel_'+output+ ('_cpx_only' if cpx_only else '_cpx_liq') + ('_pwlr_' if pwlt else '_') +'.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cca95b-2851-4e71-b8e7-29bab43fe0ad",
   "metadata": {},
   "source": [
    "#### Number of estimator and Number of new synthetic instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90efd806-6d90-4f1d-98ce-353bfab592a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=datetime.now() \n",
    "num_estimators_tot = []\n",
    "n_pert_tot = []\n",
    "score_perturb_train_val_tot = []\n",
    "score_train_val_tot = []\n",
    "\n",
    "for j in [1,5,10,15,20]:  \n",
    "    for i in range(100,340,20):\n",
    "    \n",
    "        score_perturb_train_val = ET_train_validation_balanced_perturbation(\n",
    "                                        X_train,y_train\n",
    "                                        ,std_dev_perc\n",
    "                                        ,bins\n",
    "                                        ,k_fold=10#10\n",
    "                                        ,max_depth=15\n",
    "                                        ,n_estimators=i\n",
    "                                        ,n_perturbations=j)#j*5\n",
    "        score_train_val = ET_train_validation_balanced(X_train,y_train\n",
    "                                              ,bins,k_fold=10,n_estimators=i,max_depth=15)#10 k_fold\n",
    "        num_estimators_tot.append(i)\n",
    "        n_pert_tot.append(j)#*5\n",
    "        score_perturb_train_val_tot.append(score_perturb_train_val)\n",
    "        score_train_val_tot.append(score_train_val)\n",
    "        \n",
    "        print('n_estimators:',i,', n-pert:', j)#j*5\n",
    "        print('score-model-perturb_train_val:',score_perturb_train_val)\n",
    "        print('score-model_train_val:',score_train_val)\n",
    "        print('################')\n",
    "print(datetime.now()-start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f49653-4d6c-44fb-acdc-4b42274d113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_score_perturb_train_val_tot = [score[1] for score in score_perturb_train_val_tot]\n",
    "\n",
    "fig, (ax) = plt.subplots(nrows=1, ncols=1, constrained_layout=True, figsize=(6, 5))\n",
    "sns.lineplot(x=num_estimators_tot, y=numeric_score_perturb_train_val_tot, hue=n_pert_tot)\n",
    "ax.set_xlabel('Number of Estimators')\n",
    "ax.set_ylabel('Score model')\n",
    "ax.grid(color='#B2B2B2', linestyle='--', linewidth=0.5, alpha=0.4)\n",
    "ax.legend(title='N. new synthetic \\ninstances\\n Max.Depth = 15', loc='lower right')\n",
    "ax.set_xlim(95,325)\n",
    "ax.set_box_aspect(1)\n",
    "#plt.savefig('Figures/'+'n_perturbations_n_estimators'+output+ ('_cpx_only' if cpx_only else '_cpx_liq') + ('_pwlr_' if pwlt else '_') +'.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f77dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Train & Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4313eca6",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1d8bc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T11:34:54.702939Z",
     "start_time": "2024-03-14T11:34:54.695314Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "n_perturbations_train = 15\n",
    "n_estimators_ET = 200\n",
    "max_depth_ET = 15\n",
    "n_estimators_RF = 3\n",
    "max_depth_RF = 16\n",
    "bias_split = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef2bcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T11:34:57.601012Z",
     "start_time": "2024-03-14T11:34:54.861739Z"
    }
   },
   "outputs": [],
   "source": [
    "train_2_size = 0.2\n",
    "X_train_1, X_train_2, y_train_1, y_train_2, train_index_1, train_index_2 = balanced_train_test(X,y,bins,train_2_size, sample_names)\n",
    "\n",
    "\n",
    "X_train_perturb_1, y_train_perturb_1, groups_train_1 = perturbation(X_train_1\n",
    "                                                              ,y_train_1\n",
    "                                                              ,std_dev_perc\n",
    "                                                              ,n_perturbations=n_perturbations_train)\n",
    "\n",
    "X_train_perturb_2, y_train_perturb_2, groups_train_2 = perturbation(X_train_2\n",
    "                                                              ,y_train_2\n",
    "                                                              ,std_dev_perc\n",
    "                                                              ,n_perturbations=n_perturbations_train)\n",
    "\n",
    "if pwlt:\n",
    "    X_train_perturb_s_1 = pwlt_transformation(X_train_perturb_1)\n",
    "    X_train_s_1 = pwlt_transformation(X_train_1)\n",
    "    \n",
    "    X_train_perturb_s_2 = pwlt_transformation(X_train_perturb_2)\n",
    "    X_train_s_2 = pwlt_transformation(X_train_2)\n",
    "else:\n",
    "    X_train_perturb_s_1 = scaler.transform(X_train_perturb_1)\n",
    "    X_train_s_1 = scaler.transform(X_train_1)\n",
    "    \n",
    "    X_train_perturb_s_2 = scaler.transform(X_train_perturb_2)\n",
    "    X_train_s_2 = scaler.transform(X_train_2)\n",
    "    \n",
    "\n",
    "model_perturb = ExtraTreesRegressor(n_estimators=n_estimators_ET, max_depth=max_depth_ET)\n",
    "model_perturb.fit(X_train_perturb_s_1,y_train_perturb_1)\n",
    "\n",
    "model = ExtraTreesRegressor(n_estimators=n_estimators_ET, max_depth=max_depth_ET)\n",
    "model.fit(X_train_s_1,y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edefff6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T11:35:01.426066Z",
     "start_time": "2024-03-14T11:35:01.146688Z"
    }
   },
   "outputs": [],
   "source": [
    "if bias: \n",
    "        \n",
    "    popt_bias_perturb_I, popt_bias_perturb_II, ang_left, ang_right =  piecewise_line(bias_split,\n",
    "                                                                                     X_train_perturb_s_2,\n",
    "                                                                                     y_train_perturb_2,\n",
    "                                                                                     model_perturb)\n",
    "    popt_bias_I, popt_bias_II, ang_left, ang_right =  piecewise_line(bias_split,\n",
    "                                                                     X_train_s_2,\n",
    "                                                                     y_train_2,\n",
    "                                                                     model)\n",
    "    \n",
    "    bias_perturb_params = {\n",
    "    'slope' :\n",
    "        {\n",
    "            'left' : popt_bias_I.tolist(),\n",
    "            'right' : popt_bias_II.tolist()\n",
    "        },\n",
    "    'angle' :\n",
    "        {\n",
    "            'left' : ang_left,\n",
    "            'right' : ang_right\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # To save params of bias function\n",
    "    json_bias = json.dumps(bias_perturb_params)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723f076d-0b3a-45dd-a651-172d7240d670",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f5c609-32fa-44ad-ae92-2a3c3284999e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T11:35:03.464009Z",
     "start_time": "2024-03-14T11:35:03.159764Z"
    }
   },
   "outputs": [],
   "source": [
    "My_color = '#9BB0C1' if output == 'Pressure' else '#D37676'\n",
    "\n",
    "importance_model_perturb = model_perturb.feature_importances_\n",
    "forest_importances = pd.Series(importance_model_perturb, index=columns_name).sort_values(ascending=False)# works for no pwlr models\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(ax=ax, color=My_color, alpha = 0.8,\n",
    "                            edgecolor='black', width=0.8, zorder=2) #P=4CA8B1 T=3F8DF7\n",
    "ax.set_title(('Cpx: ' if cpx_only else 'Cpx_liq: ')+output, fontsize=13)\n",
    "ax.set_ylabel(\"Relative feature importance\",fontsize=12)\n",
    "ax.grid(color='#B2B2B2', linestyle='--', linewidth=0.5, alpha=0.4, zorder=1)\n",
    "fig.tight_layout()\n",
    "#plt.savefig('Figures/'+'Feature_importance'+('_cpx_only' if cpx_only else '_cpx_liq') + ('_bc_' if bias else '_')+ output+ '.pdf', format='pdf', transparent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06715be-5273-4310-9ebd-665a48f92392",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22adb5e7",
   "metadata": {},
   "source": [
    "### Test as Montecarlo simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edff0f62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T11:35:07.499953Z",
     "start_time": "2024-03-14T11:35:06.016127Z"
    }
   },
   "outputs": [],
   "source": [
    "y_perturb_pred = model_perturb.predict(X_test_perturb_s)\n",
    "y_pred = model.predict(X_test_perturb_s)\n",
    "\n",
    "score_perturb_RMSE = MSE(y_test_perturb, y_perturb_pred, squared=False)\n",
    "score_RMSE = MSE(y_test_perturb, y_pred, squared=False)\n",
    "\n",
    "lin_res_perturb = st.linregress(y_test_perturb, y_perturb_pred)\n",
    "lin_res = st.linregress(y_test_perturb, y_pred)\n",
    "\n",
    "r2_perturb = lin_res_perturb .rvalue**2\n",
    "slope_perturb = lin_res_perturb .slope\n",
    "int_perturb = lin_res_perturb .intercept\n",
    "\n",
    "r2 = lin_res.rvalue**2\n",
    "slope = lin_res.slope\n",
    "int = lin_res.intercept\n",
    "\n",
    "\n",
    "print('Test Monte Carlo')\n",
    "print('Model-perturb')\n",
    "print('      R^2: ',r2_perturb)\n",
    "print('      Intercept: ',int_perturb)\n",
    "print('      Slope: ',slope_perturb)\n",
    "print('      RMSE: ',score_perturb_RMSE)\n",
    "\n",
    "print('Model')\n",
    "print('      R^2: ',r2)\n",
    "print('      Intercept: ',int)\n",
    "print('      Slope: ',slope)\n",
    "print('      RMSE: ',score_RMSE)\n",
    "\n",
    "\n",
    "\n",
    "unique_y_perturb_pred = np.apply_along_axis(np.median,1, np.split(y_perturb_pred,len(y_perturb_pred)/p))\n",
    "unique_y_pred = np.apply_along_axis(np.median,1, np.split(y_pred,len(y_pred)/p))\n",
    "\n",
    "unique_y_perturb_error_maxPerc = np.apply_along_axis(max_perc,1, np.split(y_perturb_pred,len(y_perturb_pred)/p))\n",
    "unique_y_perturb_error_minPerc = np.apply_along_axis(min_perc,1, np.split(y_perturb_pred,len(y_perturb_pred)/p))\n",
    "unique_y_error_maxPerc = np.apply_along_axis(max_perc,1, np.split(y_perturb_pred,len(y_pred)/p))\n",
    "unique_y_error_minPerc = np.apply_along_axis(min_perc,1, np.split(y_perturb_pred,len(y_pred)/p))\n",
    "\n",
    "if bias:\n",
    "        \n",
    "    bias_perturb_temp = bias_f(unique_y_perturb_pred, \n",
    "                               ang_left, popt_bias_perturb_I, \n",
    "                               ang_right, popt_bias_perturb_II)\n",
    "    bias_temp = bias_f(unique_y_pred,\n",
    "                       ang_left, popt_bias_I, \n",
    "                       ang_right, popt_bias_II)\n",
    "\n",
    "    \n",
    "    unique_y_perturb_pred = unique_y_perturb_pred - bias_perturb_temp\n",
    "    unique_y_pred = unique_y_pred - bias_temp\n",
    "    \n",
    "    unique_y_perturb_error_maxPerc = unique_y_perturb_error_maxPerc - bias_perturb_temp   \n",
    "    unique_y_perturb_error_minPerc = unique_y_perturb_error_minPerc - bias_perturb_temp\n",
    "    unique_y_error_maxPerc = unique_y_error_maxPerc - bias_temp\n",
    "    unique_y_error_minPerc = unique_y_error_minPerc - bias_temp\n",
    "\n",
    "\n",
    "predictions = pd.DataFrame(data=np.transpose(np.array([unique_y_perturb_pred\n",
    "                                                       ,unique_y_perturb_error_maxPerc\n",
    "                                                       ,unique_y_perturb_error_minPerc\n",
    "                                                       ,unique_y_pred\n",
    "                                                       ,unique_y_error_maxPerc\n",
    "                                                       ,unique_y_error_minPerc\n",
    "                                                       ,y_test])),    \n",
    "             index=test_index,\n",
    "             columns=['Pred_perturb'\n",
    "                      ,'Error_perturb_maxPerc'\n",
    "                      ,'Error_perturb_minPerc'\n",
    "                      ,'Pred'\n",
    "                      ,'Error_maxPerc'\n",
    "                      ,'Error_minPerc'\n",
    "                      ,'Real_value'])  \n",
    "\n",
    "\n",
    "score_perturb_RMSE_median = MSE(y_test, unique_y_perturb_pred, squared=False)\n",
    "lin_res_perturb_median = st.linregress(y_test, unique_y_perturb_pred)\n",
    "r2_perturb_median = lin_res_perturb_median.rvalue**2\n",
    "slope_perturb_median = lin_res_perturb_median.slope\n",
    "int_perturb_median = lin_res_perturb_median.intercept\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Model-perturb-median')\n",
    "print('      R^2: ',r2_perturb_median)\n",
    "print('      Intercept: ',int_perturb_median)\n",
    "print('      Slope: ',slope_perturb_median)\n",
    "print('      RMSE: ',score_perturb_RMSE_median)\n",
    "\n",
    "\n",
    "print('Predictions')\n",
    "print(predictions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0136565c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01271135-a4ab-4918-924b-8cdd6a0b7d99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T11:35:20.289404Z",
     "start_time": "2024-03-14T11:35:20.281024Z"
    }
   },
   "outputs": [],
   "source": [
    "My_color = '#9BB0C1' if output == 'Pressure' else '#D37676'\n",
    "My_ecolor = 'grey' \n",
    "unit = 'kbar' if output == 'Pressure' else '°C'\n",
    "width =1 if output=='Pressure' else 25\n",
    "inc = 1 if output=='Pressure' else 35 \n",
    "inc_top  = 3 if output=='Pressure' else 90\n",
    "a= 3 if output=='Pressure' else 1\n",
    "ylim = 6 if output=='Pressure' else 100 \n",
    "ylim_l = 3 if output=='Pressure' else 100\n",
    "facecolor = '#35374B' if output=='Pressure' else '#7D0A0A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb9ab3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T11:35:21.143975Z",
     "start_time": "2024-03-14T11:35:20.899296Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1,ncols=1, constrained_layout=True, figsize=(5, 5))\n",
    "\n",
    "fig.suptitle('Test dataset' + (' cpx' if cpx_only else ' cpx-liq') + ('_bc' if bias else ' '), fontsize=18)  \n",
    "\n",
    "ax.errorbar(y_test, unique_y_perturb_pred,\n",
    "            yerr=[unique_y_perturb_pred-unique_y_perturb_error_minPerc,\n",
    "                  unique_y_perturb_error_maxPerc-unique_y_perturb_pred],\n",
    "            linestyle='', marker = 'o',capsize=0,\n",
    "             color = My_color, markersize = 5.5, markeredgecolor='black',markeredgewidth=0.4,elinewidth=1,\n",
    "             ecolor = My_ecolor, alpha = 0.8)\n",
    "\n",
    "ax.plot((np.min(y_test),np.max(y_test)),\n",
    "        (np.min(y_test),np.max(y_test)), linestyle = '--', color ='black')\n",
    "\n",
    "ax.set_xlim(np.min(y_test)-ylim_l,np.max(y_test)+ylim)\n",
    "ax.set_ylim(np.min(y_test)-ylim_l,np.max(y_test)+ylim)\n",
    "ax.set_xlabel('Expected '+output +' ['+unit+']',fontsize=13)\n",
    "ax.set_ylabel('Predicted '+output+' ['+unit+']',fontsize=13)\n",
    "ax.set_title(('Bias corrected: ' if bias else 'No Bias corrected: ')+output, fontsize=14)\n",
    "ax.legend(title = r'R$^2$ = {:.2f}'.format(r2_perturb_median) + '\\n' +  \n",
    "                  ('RMSE = {:.0f} ' if output == 'Temperature' else 'RMSE = {:.1f} ').format(score_perturb_RMSE_median) + unit + '\\n' + \n",
    "                  'Slope = {:.1f}'.format(slope_perturb_median) + '\\n' + \n",
    "                  'Int = {:.1f}'.format(int_perturb_median), loc='lower right', title_fontsize=12) \n",
    "\n",
    "ax.tick_params(axis='y', labelsize=12)\n",
    "ax.tick_params(axis='x', labelsize=12)\n",
    "ax.grid(color='#B2B2B2', linestyle='--', linewidth=0.5, alpha=0.4)\n",
    "ax.set_box_aspect(1)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Figures/'+'Test_predictions' +('_cpx_only' if cpx_only else '_cpx_liq') + ('_bc_' if bias else '_')+ output+ '.pdf', format='pdf', transparent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835404a8-077b-430f-8027-44399e9f4022",
   "metadata": {},
   "source": [
    "#### Sectioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dbc9b6-b217-4efc-9793-2a9d9d8aa916",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1,ncols=1, constrained_layout=True, figsize=(5, 5))\n",
    "\n",
    "fig.suptitle('Test dataset' + (' cpx' if cpx_only else ' cpx-liq') + ('_bc' if bias else ' '), fontsize=18) \n",
    "\n",
    "ax.errorbar(y_test, unique_y_perturb_pred,\n",
    "            yerr=[unique_y_perturb_pred-unique_y_perturb_error_minPerc,\n",
    "                  unique_y_perturb_error_maxPerc-unique_y_perturb_pred],\n",
    "            linestyle='', marker = 'o',capsize=0,\n",
    "             color = My_color, markersize = 5.5, markeredgecolor='black',markeredgewidth=0.4,elinewidth=1,\n",
    "             ecolor = My_ecolor, alpha = 0.8, zorder= 1)\n",
    "\n",
    "ax.plot((np.min(y_test),np.max(y_test)),\n",
    "        (np.min(y_test),np.max(y_test)), linestyle = '--', color ='black',  zorder= 0)\n",
    "\n",
    "\n",
    "ax.set_xlim(np.min(y_test)-ylim_l,np.max(y_test)+ylim)\n",
    "ax.set_ylim(np.min(y_test)-ylim_l,np.max(y_test)+ylim)\n",
    "\n",
    "# Create a second axis for box plots\n",
    "ax.grid(color='#B2B2B2', linestyle='--', linewidth=0.5, alpha=0.4)\n",
    "ax2 = ax.twiny()\n",
    "\n",
    "# Create intervals\n",
    "interval_1 = (np.min(y_test), \n",
    "             min(y_train_perturb_2)+(1*(max(y_train_perturb_2)-min(y_train_perturb_2))/(a*bias_split)))\n",
    "interval_4 = (max(y_train_perturb_2)-(1*(max(y_train_perturb_2)-min(y_train_perturb_2))/(a*bias_split)), \n",
    "              np.max(y_test))\n",
    "\n",
    "\n",
    "# Filter data points within each interval\n",
    "data_interval_1 = unique_y_perturb_pred[(y_test >= interval_1[0]) & (y_test <= interval_1[1])]\n",
    "data_interval_4 = unique_y_perturb_pred[(y_test >= interval_4[0]) & (y_test <= interval_4[1])]\n",
    "\n",
    "# Create box plots\n",
    "boxprops     = dict(linestyle='-', linewidth=0.0, color='black', facecolor=facecolor, alpha = 1)\n",
    "medianprops  = dict(linestyle='-', linewidth=0.7, color='white')\n",
    "whiskerprops = dict(linestyle='-', linewidth=0.9, color='black')\n",
    "capprops     = dict(linestyle='-', linewidth=0.5, color='black')\n",
    "\n",
    "ax2.boxplot([data_interval_1, data_interval_4],\n",
    "           positions=[interval_1[0]+((interval_1[1]-interval_1[0])/2), \n",
    "                      interval_4[0]+((interval_4[1]-interval_4[0])/2)],\n",
    "           widths=width, showfliers=False,\n",
    "           boxprops=boxprops, medianprops=medianprops,\n",
    "           whiskerprops=whiskerprops, capprops=capprops,patch_artist=True, zorder= 2)\n",
    "\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_offset(median_pred, y_true_position):\n",
    "    offset = median_pred-y_true_position\n",
    "    return  offset\n",
    "\n",
    "# Calculate metrics for each interval\n",
    "offset_interval_1 = calculate_offset(np.median(unique_y_perturb_pred[(y_test >= interval_1[0]) & (y_test <= interval_1[1])]),\n",
    "                                       interval_1[0]+((interval_1[1]-interval_1[0])/2))\n",
    "\n",
    "offset_interval_4 = calculate_offset(np.median(unique_y_perturb_pred[(y_test >= interval_4[0]) & (y_test <= interval_4[1])]),\n",
    "                                       interval_4[0]+((interval_4[1]-interval_4[0])/2))\n",
    "\n",
    "# Display or use the metrics as needed\n",
    "print(\"Metrics for Interval 1:\", offset_interval_1)\n",
    "print(\"Metrics for Interval 4:\", offset_interval_4)\n",
    "\n",
    "\n",
    "# Add legends for each interval\n",
    "font_size = 7\n",
    "ax2.annotate(f\"Interval 1\\nOffset = {offset_interval_1:.1f}\",\n",
    "             xy=(interval_1[0]+((interval_1[1]-interval_1[0])/2)-inc, np.max(y_test)+ inc_top),\n",
    "             xytext=(10, -10),\n",
    "             textcoords=\"offset points\",\n",
    "             ha='center', va='top',\n",
    "             bbox=dict(boxstyle='round', alpha=0.5, facecolor='white',edgecolor='grey'),fontsize=font_size)\n",
    "          \n",
    "ax2.annotate(f\"Interval 2\\nOffset = {offset_interval_4:.1f}\",\n",
    "             xy=(interval_4[0]+((interval_4[1]-interval_4[0])/2)-inc, np.max(y_test)+ inc_top),\n",
    "             xytext=(10, -10),\n",
    "             textcoords=\"offset points\",\n",
    "             ha='center', va='top',\n",
    "             bbox=dict(boxstyle='round', alpha=0.5, facecolor='white',edgecolor='grey'),fontsize=font_size)\n",
    "\n",
    "\n",
    "ax2.axvline(x=interval_1[0],linestyle='--', linewidth=1.2, color='#7D7C7C', alpha=0.7)\n",
    "ax2.axvline(x=interval_1[1],linestyle='--', linewidth=1.2, color='#7D7C7C', alpha=0.7)\n",
    "ax2.axvline(x=interval_4[0],linestyle='--', linewidth=1.2, color='#7D7C7C', alpha=0.7)\n",
    "ax2.axvline(x=interval_4[1],linestyle='--', linewidth=1.2, color='#7D7C7C', alpha=0.7)\n",
    "\n",
    "ax2.set_xlim(np.min(y_test)-ylim_l,np.max(y_test)+ylim)\n",
    "ax2.set_ylim(np.min(y_test)-ylim_l,np.max(y_test)+ylim)\n",
    "\n",
    "\n",
    "ax.set_xlabel('Expected '+output +' ['+unit+']')\n",
    "ax.set_ylabel('Predicted '+output +' ['+unit+']')\n",
    "ax.set_title(('Bias corrected: ' if bias else 'No Bias corrected: ')+output, fontsize=14)\n",
    "\n",
    "ax.set_box_aspect(1)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Figures/'+'Test_predictions' +('_cpx_only' if cpx_only else '_cpx_liq') + ('_bc_' if bias else '_')+ output+ '_boxplots.pdf', format='pdf', transparent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39717929",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ee87d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T11:35:49.432925Z",
     "start_time": "2024-03-14T11:35:47.778185Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "initial_type = [('float_input', FloatTensorType([None, X_train_perturb_s_1.shape[1]]))] \n",
    "model_onx = convert_sklearn(model_perturb, initial_types=initial_type,target_opset=12)\n",
    "\n",
    " \n",
    "if output == 'Pressure' and cpx_only and bias ==True:\n",
    "    with open(\"models/\"+\"Model_cpx_only_P_bias.onnx\", \"wb\") as f:\n",
    "        f.write(model_onx.SerializeToString())\n",
    "    with open(\"models/\"+\"Model_cpx_only_P_bias.json\", \"w\") as outfile:\n",
    "            json.dump(json_bias, outfile)\n",
    "    with open(\"models/\"+\"Model_cpx_only_P_bias.joblib\", \"wb\") as outfile:\n",
    "            joblib.dump(scaler, outfile)\n",
    "  \n",
    "    \n",
    "elif output == 'Temperature' and cpx_only and bias ==True:\n",
    "    with open(\"models/\"+\"Model_cpx_only_T_bias.onnx\", \"wb\") as f:\n",
    "        f.write(model_onx.SerializeToString())\n",
    "    with open(\"models/\"+\"Model_cpx_only_T_bias.json\", \"w\") as outfile:\n",
    "        json.dump(json_bias, outfile)\n",
    "    with open(\"models/\"+\"Model_cpx_only_T_bias.joblib\", \"wb\") as outfile:\n",
    "            joblib.dump(scaler, outfile)\n",
    "\n",
    "\n",
    "elif output == 'Pressure' and cpx_only==False and bias ==True:\n",
    "    with open(\"models/\"+\"Model_cpx_liquid_P_bias.onnx\", \"wb\") as f:\n",
    "        f.write(model_onx.SerializeToString())\n",
    "        with open(\"models/\"+\"Model_cpx_liquid_P_bias.json\", \"w\") as outfile:\n",
    "            json.dump(json_bias, outfile)\n",
    "        with open(\"models/\"+\"Model_cpx_liquid_P_bias.joblib\", \"wb\") as outfile:\n",
    "            joblib.dump(scaler, outfile)\n",
    "\n",
    "elif output == 'Temperature' and cpx_only==False and bias ==True:\n",
    "    with open(\"models/\"+\"Model_cpx_liquid_T_bias.onnx\", \"wb\") as f:\n",
    "        f.write(model_onx.SerializeToString())\n",
    "        with open(\"models/\"+\"Model_cpx_liquid_T_bias.json\", \"w\") as outfile:\n",
    "            json.dump(json_bias, outfile)\n",
    "        with open(\"models/\"+\"Model_cpx_liquid_T_bias.joblib\", \"wb\") as outfile:\n",
    "            joblib.dump(scaler, outfile)\n",
    "    \n",
    "            \n",
    "#No bias   \n",
    "elif output == 'Pressure' and cpx_only and bias ==False:\n",
    "    with open(\"models/\"+\"Model_cpx_only_P.onnx\", \"wb\") as f:\n",
    "        f.write(model_onx.SerializeToString())\n",
    "    with open(\"models/\"+\"Model_cpx_only_P.joblib\", \"wb\") as outfile:\n",
    "        joblib.dump(scaler, outfile)\n",
    "        \n",
    "elif output == 'Temperature' and cpx_only and bias ==False:\n",
    "    with open(\"models/\"+\"Model_cpx_only_T.onnx\", \"wb\") as f:\n",
    "        f.write(model_onx.SerializeToString())\n",
    "    with open(\"models/\"+\"Model_cpx_only_T.joblib\", \"wb\") as outfile:\n",
    "        joblib.dump(scaler, outfile)\n",
    "\n",
    "elif output == 'Pressure' and cpx_only==False and bias ==False:\n",
    "    with open(\"models/\"+\"Model_cpx_liq_P.onnx\", \"wb\") as f:\n",
    "        f.write(model_onx.SerializeToString())\n",
    "    with open(\"models/\"+\"Model_cpx_liq_P.joblib\", \"wb\") as outfile:\n",
    "        joblib.dump(scaler, outfile)\n",
    "  \n",
    "elif output == 'Temperature' and cpx_only==False and bias ==False:\n",
    "    with open(\"models/\"+\"Model_cpx_liq_T.onnx\", \"wb\") as f:\n",
    "        f.write(model_onx.SerializeToString())\n",
    "    with open(\"models/\"+\"Model_cpx_liq_T.joblib\", \"wb\") as outfile:\n",
    "        joblib.dump(scaler, outfile)\n",
    "\n",
    "else:\n",
    "    print('We can just manage Pressure or Temperature')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add06e1c-0df0-4252-a6ae-be57d1cf99d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
